{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxAnjwkjXKYFCnzum8L7PO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7GbeaZKp6wO",
        "outputId": "a6b292b3-1f60-4389-98bb-b9bc5499e8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 87% 248M/285M [00:00<00:00, 779MB/s] \n",
            "100% 285M/285M [00:00<00:00, 783MB/s]\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# download the data from kaggle and unzip\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "!cp /content/drive/MyDrive/cs231n/kaggle_API/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "\n",
        "# install wandb if not present\n",
        "! pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "from torchsummary import summary\n",
        "\n",
        "wandb.init(project=\"ml_assignment_4\", name=\"cnn-5\")\n",
        "\n",
        "# Hyperparameters\n",
        "config = {\n",
        "    \"epochs\": 25,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"image_size\": 48,\n",
        "    \"num_classes\": 7,\n",
        "}\n",
        "wandb.config.update(config)\n",
        "\n",
        "\n",
        "# Dataset class\n",
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.df.iloc[idx]['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)\n",
        "        label = int(self.df.iloc[idx]['emotion']) if 'emotion' in self.df.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_df = pd.read_csv(os.path.expanduser(\"/content/train.csv\"))\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.1, stratify=train_df['emotion'], random_state=42)\n",
        "\n",
        "train_dataset = FacialExpressionDataset(train_data, transform=transform)\n",
        "val_dataset = FacialExpressionDataset(val_data, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "# Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "          # Block 1 - bigger\n",
        "          nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64), nn.ReLU(),\n",
        "          nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64), nn.ReLU(),\n",
        "          nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(64), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (64, 24, 24)\n",
        "\n",
        "          # Block 2 - bigger\n",
        "          nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(128), nn.ReLU(),\n",
        "          nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(128), nn.ReLU(),\n",
        "          nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(128), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (128, 12, 12)\n",
        "\n",
        "          # Block 3 - bigger\n",
        "          nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(256), nn.ReLU(),\n",
        "          nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(256), nn.ReLU(),\n",
        "          nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(256), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (256, 6, 6)\n",
        "\n",
        "          # additional Block 4\n",
        "          nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(512), nn.ReLU(),\n",
        "          nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "          nn.BatchNorm2d(512), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (512, 3, 3)\n",
        "\n",
        "          # FC layers - bigger\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(512 * 3 * 3, 1024),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.4),\n",
        "          nn.Linear(1024, 512),\n",
        "          nn.ReLU(),\n",
        "          nn.Dropout(0.3),\n",
        "          nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(num_classes=config[\"num_classes\"]).to(device)\n",
        "\n",
        "# log the model summary\n",
        "\n",
        "f = io.StringIO()\n",
        "with redirect_stdout(f):\n",
        "    summary(model, input_size=(1, 48, 48))\n",
        "model_summary_str = f.getvalue()\n",
        "\n",
        "print(model_summary_str)\n",
        "\n",
        "# Log to wandb as formatted HTML (nicely viewable in UI)\n",
        "wandb.log({\"model_summary\": wandb.Html(f\"<pre>{model_summary_str}</pre>\")})\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    model.train()\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_acc += (preds == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            val_acc += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc /= len(val_loader.dataset)\n",
        "\n",
        "    # Log to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "# Save and log model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "wandb.save(\"model.pth\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Fof5XptqEwS",
        "outputId": "540113c6-a877-449f-f36b-9d59b60c31f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_175251-nc7tc9gf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/nc7tc9gf' target=\"_blank\">cnn-5</a></strong> to <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/nc7tc9gf' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/nc7tc9gf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 48, 48]             640\n",
            "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
            "              ReLU-3           [-1, 64, 48, 48]               0\n",
            "            Conv2d-4           [-1, 64, 48, 48]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 48, 48]             128\n",
            "              ReLU-6           [-1, 64, 48, 48]               0\n",
            "            Conv2d-7           [-1, 64, 48, 48]          36,928\n",
            "       BatchNorm2d-8           [-1, 64, 48, 48]             128\n",
            "              ReLU-9           [-1, 64, 48, 48]               0\n",
            "        MaxPool2d-10           [-1, 64, 24, 24]               0\n",
            "           Conv2d-11          [-1, 128, 24, 24]          73,856\n",
            "      BatchNorm2d-12          [-1, 128, 24, 24]             256\n",
            "             ReLU-13          [-1, 128, 24, 24]               0\n",
            "           Conv2d-14          [-1, 128, 24, 24]         147,584\n",
            "      BatchNorm2d-15          [-1, 128, 24, 24]             256\n",
            "             ReLU-16          [-1, 128, 24, 24]               0\n",
            "           Conv2d-17          [-1, 128, 24, 24]         147,584\n",
            "      BatchNorm2d-18          [-1, 128, 24, 24]             256\n",
            "             ReLU-19          [-1, 128, 24, 24]               0\n",
            "        MaxPool2d-20          [-1, 128, 12, 12]               0\n",
            "           Conv2d-21          [-1, 256, 12, 12]         295,168\n",
            "      BatchNorm2d-22          [-1, 256, 12, 12]             512\n",
            "             ReLU-23          [-1, 256, 12, 12]               0\n",
            "           Conv2d-24          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-25          [-1, 256, 12, 12]             512\n",
            "             ReLU-26          [-1, 256, 12, 12]               0\n",
            "           Conv2d-27          [-1, 256, 12, 12]         590,080\n",
            "      BatchNorm2d-28          [-1, 256, 12, 12]             512\n",
            "             ReLU-29          [-1, 256, 12, 12]               0\n",
            "        MaxPool2d-30            [-1, 256, 6, 6]               0\n",
            "           Conv2d-31            [-1, 512, 6, 6]       1,180,160\n",
            "      BatchNorm2d-32            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-33            [-1, 512, 6, 6]               0\n",
            "           Conv2d-34            [-1, 512, 6, 6]       2,359,808\n",
            "      BatchNorm2d-35            [-1, 512, 6, 6]           1,024\n",
            "             ReLU-36            [-1, 512, 6, 6]               0\n",
            "        MaxPool2d-37            [-1, 512, 3, 3]               0\n",
            "          Flatten-38                 [-1, 4608]               0\n",
            "           Linear-39                 [-1, 1024]       4,719,616\n",
            "             ReLU-40                 [-1, 1024]               0\n",
            "          Dropout-41                 [-1, 1024]               0\n",
            "           Linear-42                  [-1, 512]         524,800\n",
            "             ReLU-43                  [-1, 512]               0\n",
            "          Dropout-44                  [-1, 512]               0\n",
            "           Linear-45                    [-1, 7]           3,591\n",
            "================================================================\n",
            "Total params: 10,711,559\n",
            "Trainable params: 10,711,559\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 19.16\n",
            "Params size (MB): 40.86\n",
            "Estimated Total Size (MB): 60.03\n",
            "----------------------------------------------------------------\n",
            "\n",
            "Epoch 1: Train Acc=0.2460, Val Acc=0.2800\n",
            "Epoch 2: Train Acc=0.2988, Val Acc=0.3034\n",
            "Epoch 3: Train Acc=0.3566, Val Acc=0.4121\n",
            "Epoch 4: Train Acc=0.4252, Val Acc=0.4354\n",
            "Epoch 5: Train Acc=0.4544, Val Acc=0.4716\n",
            "Epoch 6: Train Acc=0.4826, Val Acc=0.5141\n",
            "Epoch 7: Train Acc=0.5099, Val Acc=0.5085\n",
            "Epoch 8: Train Acc=0.5267, Val Acc=0.5354\n",
            "Epoch 9: Train Acc=0.5498, Val Acc=0.5462\n",
            "Epoch 10: Train Acc=0.5653, Val Acc=0.5507\n",
            "Epoch 11: Train Acc=0.5862, Val Acc=0.5545\n",
            "Epoch 12: Train Acc=0.6000, Val Acc=0.5622\n",
            "Epoch 13: Train Acc=0.6120, Val Acc=0.5670\n",
            "Epoch 14: Train Acc=0.6357, Val Acc=0.5785\n",
            "Epoch 15: Train Acc=0.6434, Val Acc=0.5737\n",
            "Epoch 16: Train Acc=0.6709, Val Acc=0.5834\n",
            "Epoch 17: Train Acc=0.6866, Val Acc=0.5977\n",
            "Epoch 18: Train Acc=0.7057, Val Acc=0.5594\n",
            "Epoch 19: Train Acc=0.7254, Val Acc=0.5859\n",
            "Epoch 20: Train Acc=0.7429, Val Acc=0.6015\n",
            "Epoch 21: Train Acc=0.7590, Val Acc=0.5980\n",
            "Epoch 22: Train Acc=0.7804, Val Acc=0.6169\n",
            "Epoch 23: Train Acc=0.8013, Val Acc=0.5907\n",
            "Epoch 24: Train Acc=0.8141, Val Acc=0.6151\n",
            "Epoch 25: Train Acc=0.8357, Val Acc=0.6141\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>train_accuracy</td><td>▁▂▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▇▇▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▄▄▅▆▆▆▇▇▇▇▇▇▇▇█▇▇███▇██</td></tr><tr><td>val_loss</td><td>█▇▅▄▄▃▃▂▂▁▂▁▁▁▁▁▁▂▁▂▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>25</td></tr><tr><td>train_accuracy</td><td>0.83567</td></tr><tr><td>train_loss</td><td>0.48098</td></tr><tr><td>val_accuracy</td><td>0.61407</td></tr><tr><td>val_loss</td><td>1.19779</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cnn-5</strong> at: <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/nc7tc9gf' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/nc7tc9gf</a><br> View project at: <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_175251-nc7tc9gf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gz_HXymmqElB"
      }
    }
  ]
}