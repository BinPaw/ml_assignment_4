{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGE5wY7G1v23RMIQsWoNCu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7GbeaZKp6wO",
        "outputId": "40dba10e-9d4a-4ac3-c0c1-de5c113bc6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 85% 242M/285M [00:00<00:00, 801MB/s] \n",
            "100% 285M/285M [00:01<00:00, 235MB/s]\n",
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# download the data from kaggle and unzip\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "!cp /content/drive/MyDrive/cs231n/kaggle_API/kaggle.json ~/.kaggle/kaggle.json\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
        "\n",
        "# install wandb if not present\n",
        "! pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "from torchsummary import summary\n",
        "\n",
        "wandb.init(project=\"ml_assignment_4\", name=\"cnn-2\")\n",
        "\n",
        "# Hyperparameters\n",
        "config = {\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"image_size\": 48,\n",
        "    \"num_classes\": 7,\n",
        "}\n",
        "wandb.config.update(config)\n",
        "\n",
        "\n",
        "# Dataset class\n",
        "class FacialExpressionDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.df = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = np.array(self.df.iloc[idx]['pixels'].split(), dtype=np.uint8).reshape(48, 48)\n",
        "        image = Image.fromarray(pixels)\n",
        "        label = int(self.df.iloc[idx]['emotion']) if 'emotion' in self.df.columns else -1\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "train_df = pd.read_csv(os.path.expanduser(\"/content/train.csv\"))\n",
        "train_data, val_data = train_test_split(train_df, test_size=0.1, stratify=train_df['emotion'], random_state=42)\n",
        "\n",
        "train_dataset = FacialExpressionDataset(train_data, transform=transform)\n",
        "val_dataset = FacialExpressionDataset(val_data, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "# Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "          # Block 1\n",
        "          nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (32, 24, 24)\n",
        "\n",
        "          # Block 2\n",
        "          nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (64, 12, 12)\n",
        "\n",
        "          # Block 3\n",
        "          nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=2),  # -> (128, 6, 6)\n",
        "\n",
        "          # FC layers\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(128 * 6 * 6, 512), nn.ReLU(),\n",
        "          nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Net(num_classes=config[\"num_classes\"]).to(device)\n",
        "\n",
        "# log the model summary\n",
        "\n",
        "f = io.StringIO()\n",
        "with redirect_stdout(f):\n",
        "    summary(model, input_size=(1, 48, 48))\n",
        "model_summary_str = f.getvalue()\n",
        "\n",
        "# Log to wandb as formatted HTML (nicely viewable in UI)\n",
        "wandb.log({\"model_summary\": wandb.Html(f\"<pre>{model_summary_str}</pre>\")})\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    model.train()\n",
        "    running_loss, running_acc = 0.0, 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_acc += (preds == labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_acc = running_acc / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            val_acc += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc /= len(val_loader.dataset)\n",
        "\n",
        "    # Log to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_acc,\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
        "\n",
        "# Save and log model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "wandb.save(\"model.pth\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "3Fof5XptqEwS",
        "outputId": "e4806cff-6b24-4c3d-fece-545bfbbeef18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbinpaw\u001b[0m (\u001b[33mbinpaw-free-university-of-tbilisi-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_152725-93hohr3o</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/93hohr3o' target=\"_blank\">cnn-2</a></strong> to <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/93hohr3o' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/93hohr3o</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Acc=0.2843, Val Acc=0.3703\n",
            "Epoch 2: Train Acc=0.4415, Val Acc=0.4876\n",
            "Epoch 3: Train Acc=0.5183, Val Acc=0.5322\n",
            "Epoch 4: Train Acc=0.5704, Val Acc=0.5531\n",
            "Epoch 5: Train Acc=0.6160, Val Acc=0.5639\n",
            "Epoch 6: Train Acc=0.6695, Val Acc=0.5772\n",
            "Epoch 7: Train Acc=0.7238, Val Acc=0.5772\n",
            "Epoch 8: Train Acc=0.7902, Val Acc=0.5817\n",
            "Epoch 9: Train Acc=0.8473, Val Acc=0.5737\n",
            "Epoch 10: Train Acc=0.9030, Val Acc=0.5667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▄▄▅▅▆▇▇█</td></tr><tr><td>train_loss</td><td>█▇▆▅▅▄▃▂▂▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>▅▃▂▁▁▁▂▃▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.90305</td></tr><tr><td>train_loss</td><td>0.27843</td></tr><tr><td>val_accuracy</td><td>0.5667</td></tr><tr><td>val_loss</td><td>1.96818</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cnn-2</strong> at: <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/93hohr3o' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4/runs/93hohr3o</a><br> View project at: <a href='https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4' target=\"_blank\">https://wandb.ai/binpaw-free-university-of-tbilisi-/ml_assignment_4</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_152725-93hohr3o/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gz_HXymmqElB"
      }
    }
  ]
}